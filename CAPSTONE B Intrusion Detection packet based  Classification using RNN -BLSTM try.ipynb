{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAPSTONE B Intrusion Detection flow based  Classification using RNN -BLSTM try "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib as matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing -Transformation and Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf version\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "#tensorboard version\n",
    "from tensorboard import version; print(version.VERSION)\n",
    "#Keras version\n",
    "import keras \n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('C:\\\\Users\\\\Brook\\\\Desktop\\\\#SMU_Courses\\\\#MSDS 6130 Capstone A & B\\\\MSDS6120 CapstoneA\\\\#ProjectData&NoteBook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir : C:\\Users\\Brook\\Desktop\\#SMU_Courses\\#MSDS 6130 Capstone A & B\\MSDS6120 CapstoneA\\#ProjectData&NoteBook\n"
     ]
    }
   ],
   "source": [
    "print ( \"Current working dir : %s\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'UNSW_NB15_training_set.csv')\n",
    "test = pd.read_csv(r'UNSW_NB15_testing_set.csv')\n",
    "list_events = pd.read_csv(r'UNSW_NB15_LIST_EVENTS.csv')\n",
    "features = pd.read_csv(r'UNSW_NB15_features.csv',encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([train, test]).drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to encode string features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack cat: {'Shellcode', 'Worms', 'Backdoor', 'DoS', 'Normal', 'Analysis', 'Generic', 'Reconnaissance', 'Fuzzers', 'Exploits'}\n",
      "\n",
      "Describing attack_type: \n",
      "min 0\n",
      "max 9\n",
      "mode 0    6\n",
      "dtype: int32\n",
      "mode 0.3609225646458884 %\n",
      "looks like 6 is 'normal', but its not that common\n"
     ]
    }
   ],
   "source": [
    "le1 = LabelEncoder()\n",
    "le = LabelEncoder()\n",
    "\n",
    "vector = combined_data['attack_cat']\n",
    "\n",
    "print(\"attack cat:\", set(list(vector))) # use print to make it print on single line \n",
    "\n",
    "combined_data['attack_cat'] = le1.fit_transform(vector)\n",
    "combined_data['proto'] = le.fit_transform(combined_data['proto'])\n",
    "combined_data['service'] = le.fit_transform(combined_data['service'])\n",
    "combined_data['state'] = le.fit_transform(combined_data['state'])\n",
    "\n",
    "vector = combined_data['attack_cat']\n",
    "print('\\nDescribing attack_type: ')\n",
    "print(\"min\", vector.min())\n",
    "print(\"max\", vector.max())\n",
    "print(\"mode\",vector.mode())\n",
    "print(\"mode\", len(np.where(vector.values==6)[0])/len(vector),\"%\")\n",
    "print(\"looks like 6 is 'normal', but its not that common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Analysis', 'Backdoor', 'DoS', 'Exploits', 'Fuzzers', 'Generic',\n",
       "       'Normal', 'Reconnaissance', 'Shellcode', 'Worms'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.inverse_transform([0,1,2,3,4,5,6,7,8,9,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???? Dropping thr features of Low Standard deviation and Low corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257673, 44)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(257673, 35)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##?????\n",
    "lowSTD = list(combined_data.std().to_frame().nsmallest(6,columns=0).index)\n",
    "lowCORR = list(combined_data.corr().abs().sort_values('attack_cat')['attack_cat'].nsmallest(3).index) # .where(lambda x: x < 0.005).dropna()\n",
    "drop = set( lowCORR + lowSTD)\n",
    "#drop = {'ackdat', 'ct_ftp_cmd', 'djit', 'is_ftp_login', 'is_sm_ips_ports', 'response_body_len', 'sjit', 'synack', 'tcprtt'}\n",
    "combined_data.shape\n",
    "combined_data_reduced=combined_data.drop(drop,axis=1)\n",
    "combined_data_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>dwin</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.121478</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>252</td>\n",
       "      <td>254</td>\n",
       "      <td>14158.942380</td>\n",
       "      <td>8495.365234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.295600</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>255</td>\n",
       "      <td>621772692</td>\n",
       "      <td>2202533631</td>\n",
       "      <td>255</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.649902</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>8395.112305</td>\n",
       "      <td>503571.312500</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>49.915000</td>\n",
       "      <td>15.432865</td>\n",
       "      <td>255</td>\n",
       "      <td>1417884146</td>\n",
       "      <td>3077387971</td>\n",
       "      <td>255</td>\n",
       "      <td>52</td>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.623129</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>1572.271851</td>\n",
       "      <td>60929.230470</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>231.875571</td>\n",
       "      <td>102.737203</td>\n",
       "      <td>255</td>\n",
       "      <td>2116150707</td>\n",
       "      <td>2963114973</td>\n",
       "      <td>255</td>\n",
       "      <td>46</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.681642</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>2740.178955</td>\n",
       "      <td>3358.622070</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>152.876547</td>\n",
       "      <td>90.235726</td>\n",
       "      <td>255</td>\n",
       "      <td>1107119177</td>\n",
       "      <td>1047442890</td>\n",
       "      <td>255</td>\n",
       "      <td>52</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.449454</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>254</td>\n",
       "      <td>252</td>\n",
       "      <td>8561.499023</td>\n",
       "      <td>3987.059814</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47.750333</td>\n",
       "      <td>75.659602</td>\n",
       "      <td>255</td>\n",
       "      <td>2436137549</td>\n",
       "      <td>1977154190</td>\n",
       "      <td>255</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
       "0  0.121478    113        0      4      6      4     258     172  74.087490   \n",
       "1  0.649902    113        0      4     14     38     734   42014  78.473372   \n",
       "2  1.623129    113        0      4      8     16     364   13186  14.170161   \n",
       "3  1.681642    113        3      4     12     12     628     770  13.677108   \n",
       "4  0.449454    113        0      4     10      6     534     268  33.373826   \n",
       "\n",
       "   sttl  dttl         sload          dload  sloss  dloss      sinpkt  \\\n",
       "0   252   254  14158.942380    8495.365234      0      0   24.295600   \n",
       "1    62   252   8395.112305  503571.312500      2     17   49.915000   \n",
       "2    62   252   1572.271851   60929.230470      1      6  231.875571   \n",
       "3    62   252   2740.178955    3358.622070      1      3  152.876547   \n",
       "4   254   252   8561.499023    3987.059814      2      1   47.750333   \n",
       "\n",
       "       dinpkt  swin       stcpb       dtcpb  dwin  smean  dmean  trans_depth  \\\n",
       "0    8.375000   255   621772692  2202533631   255     43     43            0   \n",
       "1   15.432865   255  1417884146  3077387971   255     52   1106            0   \n",
       "2  102.737203   255  2116150707  2963114973   255     46    824            0   \n",
       "3   90.235726   255  1107119177  1047442890   255     52     64            0   \n",
       "4   75.659602   255  2436137549  1977154190   255     53     45            0   \n",
       "\n",
       "   ct_srv_src  ct_state_ttl  ct_dst_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
       "0           1             0           1                 1                 1   \n",
       "1          43             1           1                 1                 1   \n",
       "2           7             1           2                 1                 1   \n",
       "3           1             1           2                 1                 1   \n",
       "4          43             1           2                 2                 1   \n",
       "\n",
       "   ct_dst_src_ltm  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  attack_cat  label  \n",
       "0               1                 0           1           1           6      0  \n",
       "1               2                 0           1           6           6      0  \n",
       "2               3                 0           2           6           6      0  \n",
       "3               3                 0           2           1           6      0  \n",
       "4              40                 0           2          39           6      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "combined_data_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ackdat', 'synack', 'tcprtt', 'is_ftp_login', 'ct_ftp_cmd', 'is_sm_ips_ports']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowSTD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sjit', 'response_body_len', 'djit']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stats.stackexchange.com/questions/309612/removing-features-with-low-variance-in-classification-models\n",
    "lowCORR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spkts',\n",
       " 'dpkts',\n",
       " 'sbytes',\n",
       " 'dbytes',\n",
       " 'rate',\n",
       " 'sttl',\n",
       " 'dttl',\n",
       " 'sload',\n",
       " 'dload',\n",
       " 'sloss',\n",
       " 'dloss',\n",
       " 'sinpkt',\n",
       " 'dinpkt',\n",
       " 'swin',\n",
       " 'stcpb',\n",
       " 'dtcpb',\n",
       " 'dwin',\n",
       " 'smean',\n",
       " 'dmean',\n",
       " 'trans_depth',\n",
       " 'ct_srv_src',\n",
       " 'ct_state_ttl',\n",
       " 'ct_dst_ltm',\n",
       " 'ct_src_dport_ltm',\n",
       " 'ct_dst_sport_ltm',\n",
       " 'ct_dst_src_ltm',\n",
       " 'ct_flw_http_mthd',\n",
       " 'ct_src_ltm',\n",
       " 'ct_srv_dst',\n",
       " 'attack_cat',\n",
       " 'label']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ??????\n",
    "transform = list(combined_data_reduced.columns.values[4:])\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform.append('dur')\n",
    "transform.remove('attack_cat')\n",
    "# transform min-max norm \n",
    "combined_data_reduced[transform] = combined_data_reduced[transform].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined data reducd transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>dwin</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>label</th>\n",
       "      <th>dur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.364553e-06</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.879598e-04</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.144768</td>\n",
       "      <td>0.512828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.024634e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>1.401989e-06</td>\n",
       "      <td>0.022458</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>5.916098e-04</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.330128</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.737333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.083170e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>2.625704e-07</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>2.748269e-03</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492706</td>\n",
       "      <td>0.689918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.705215e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>4.576117e-07</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>1.811945e-03</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.257772</td>\n",
       "      <td>0.243882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.042667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.802737e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>1.429776e-06</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>5.659534e-04</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567209</td>\n",
       "      <td>0.460351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019595</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.490901e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82327</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.389445e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.926172e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.333335e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82328</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>2.072552e-05</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>6.623096e-04</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.249720</td>\n",
       "      <td>0.764699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.593919</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.843502e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.111492e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.111493e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82331</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.719141e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.066711e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500000e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257673 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          spkts     dpkts    sbytes    dbytes      rate      sttl      dttl  \\\n",
       "0      0.000470  0.000363  0.000016  0.000012  0.000074  0.988235  1.000000   \n",
       "1      0.001221  0.003449  0.000049  0.002866  0.000078  0.243137  0.992126   \n",
       "2      0.000658  0.001452  0.000024  0.000900  0.000014  0.243137  0.992126   \n",
       "3      0.001033  0.001089  0.000042  0.000053  0.000014  0.243137  0.992126   \n",
       "4      0.000845  0.000545  0.000036  0.000018  0.000033  0.996078  0.992126   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "82327  0.000094  0.000000  0.000006  0.000000  0.200000  0.996078  0.000000   \n",
       "82328  0.001785  0.000726  0.001257  0.000024  0.000024  0.996078  0.992126   \n",
       "82329  0.000000  0.000000  0.000002  0.000000  0.000000  0.000000  0.000000   \n",
       "82330  0.000000  0.000000  0.000002  0.000000  0.000000  0.000000  0.000000   \n",
       "82331  0.000094  0.000000  0.000006  0.000000  0.111111  0.996078  0.000000   \n",
       "\n",
       "              sload     dload     sloss     dloss        sinpkt    dinpkt  \\\n",
       "0      2.364553e-06  0.000379  0.000000  0.000000  2.879598e-04  0.000145   \n",
       "1      1.401989e-06  0.022458  0.000376  0.003087  5.916098e-04  0.000267   \n",
       "2      2.625704e-07  0.002717  0.000188  0.001090  2.748269e-03  0.001779   \n",
       "3      4.576117e-07  0.000150  0.000188  0.000545  1.811945e-03  0.001563   \n",
       "4      1.429776e-06  0.000178  0.000376  0.000182  5.659534e-04  0.001310   \n",
       "...             ...       ...       ...       ...           ...       ...   \n",
       "82327  1.389445e-02  0.000000  0.000000  0.000000  5.926172e-08  0.000000   \n",
       "82328  2.072552e-05  0.000100  0.001316  0.000182  6.623096e-04  0.002489   \n",
       "82329  0.000000e+00  0.000000  0.000000  0.000000  7.111492e-01  0.000000   \n",
       "82330  0.000000e+00  0.000000  0.000000  0.000000  7.111493e-01  0.000000   \n",
       "82331  7.719141e-03  0.000000  0.000000  0.000000  1.066711e-07  0.000000   \n",
       "\n",
       "       swin     stcpb     dtcpb  dwin     smean     dmean  trans_depth  \\\n",
       "0       1.0  0.144768  0.512828   1.0  0.012838  0.028667          0.0   \n",
       "1       1.0  0.330128  0.716524   1.0  0.018919  0.737333          0.0   \n",
       "2       1.0  0.492706  0.689918   1.0  0.014865  0.549333          0.0   \n",
       "3       1.0  0.257772  0.243882   1.0  0.018919  0.042667          0.0   \n",
       "4       1.0  0.567209  0.460351   1.0  0.019595  0.030000          0.0   \n",
       "...     ...       ...       ...   ...       ...       ...          ...   \n",
       "82327   0.0  0.000000  0.000000   0.0  0.018919  0.000000          0.0   \n",
       "82328   1.0  0.249720  0.764699   1.0  0.593919  0.029333          0.0   \n",
       "82329   0.0  0.000000  0.000000   0.0  0.014865  0.000000          0.0   \n",
       "82330   0.0  0.000000  0.000000   0.0  0.014865  0.000000          0.0   \n",
       "82331   0.0  0.000000  0.000000   0.0  0.018919  0.000000          0.0   \n",
       "\n",
       "       ct_srv_src  ct_state_ttl  ct_dst_ltm  ct_src_dport_ltm  \\\n",
       "0        0.000000      0.000000    0.000000          0.000000   \n",
       "1        0.677419      0.166667    0.000000          0.000000   \n",
       "2        0.096774      0.166667    0.017241          0.000000   \n",
       "3        0.000000      0.166667    0.017241          0.000000   \n",
       "4        0.677419      0.166667    0.017241          0.017241   \n",
       "...           ...           ...         ...               ...   \n",
       "82327    0.000000      0.333333    0.017241          0.000000   \n",
       "82328    0.000000      0.166667    0.017241          0.000000   \n",
       "82329    0.000000      0.333333    0.000000          0.000000   \n",
       "82330    0.000000      0.333333    0.000000          0.000000   \n",
       "82331    0.000000      0.333333    0.000000          0.000000   \n",
       "\n",
       "       ct_dst_sport_ltm  ct_dst_src_ltm  ct_flw_http_mthd  ct_src_ltm  \\\n",
       "0                   0.0        0.000000               0.0    0.000000   \n",
       "1                   0.0        0.015625               0.0    0.000000   \n",
       "2                   0.0        0.031250               0.0    0.016949   \n",
       "3                   0.0        0.031250               0.0    0.016949   \n",
       "4                   0.0        0.609375               0.0    0.016949   \n",
       "...                 ...             ...               ...         ...   \n",
       "82327               0.0        0.015625               0.0    0.016949   \n",
       "82328               0.0        0.000000               0.0    0.033898   \n",
       "82329               0.0        0.000000               0.0    0.000000   \n",
       "82330               0.0        0.000000               0.0    0.000000   \n",
       "82331               0.0        0.000000               0.0    0.000000   \n",
       "\n",
       "       ct_srv_dst  label           dur  \n",
       "0        0.000000    0.0  2.024634e-03  \n",
       "1        0.081967    0.0  1.083170e-02  \n",
       "2        0.081967    0.0  2.705215e-02  \n",
       "3        0.000000    0.0  2.802737e-02  \n",
       "4        0.622951    0.0  7.490901e-03  \n",
       "...           ...    ...           ...  \n",
       "82327    0.000000    0.0  8.333335e-08  \n",
       "82328    0.016393    0.0  1.843502e-02  \n",
       "82329    0.000000    0.0  0.000000e+00  \n",
       "82330    0.000000    0.0  0.000000e+00  \n",
       "82331    0.000000    0.0  1.500000e-07  \n",
       "\n",
       "[257673 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_reduced[transform]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = combined_data_reduced.drop(['attack_cat','label'], axis=1) # droped label\n",
    "data_y = combined_data_reduced.loc[:,['label']]\n",
    "\n",
    "# del combined_data # free mem\n",
    "# Use stratification to fix imbalance of normal vs. attack categories\n",
    "\n",
    "# we changed to 60% , 40% as the epoch is very slow for BLSTM \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, train_size=0.6,test_size=0.4, random_state = 1, stratify = data_y)\n",
    "\n",
    "#https://www.bitdegree.org/learn/train-test-split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=.70, random_state=42) # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_data_reduced[transform].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array has non-zero items too\n"
     ]
    }
   ],
   "source": [
    "is_all_zero = np.all((data_y == 0))\n",
    "if is_all_zero:\n",
    "    print('Array contains only 0')\n",
    "else:\n",
    "    print('Array has non-zero items too')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154603, 33)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(154603, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(103070, 33)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(103070, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after we split to 70 /30 to combine dataset\n",
    "\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape # test is larger... good \n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark before additional feature removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.93582 for the DecisionTreeClassifier\n",
      "Acc: 0.94784 for the RandomForestClassifier\n",
      "Acc: 0.94372 for the ExtraTreesClassifier\n"
     ]
    }
   ],
   "source": [
    "#import xgboost \n",
    "#import lightgbm\n",
    "\n",
    "# DTC = DecisionTreeClassifier()\n",
    "# RFC = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1)\n",
    "# ETC = ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Feature selection methods deployed , DTC , RFC , ETC \n",
    "DTC = DecisionTreeClassifier() \n",
    "RFC = RandomForestClassifier(n_estimators=25, random_state=1)\n",
    "ETC = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_features='auto', bootstrap=False)\n",
    "\n",
    "\n",
    "#XGB = xgboost.XGBClassifier(n_estimators=150, n_jobs=-1)\n",
    "#GBM = lightgbm.LGBMClassifier(objective='binary', n_estimators= 500) # multiclass\n",
    "\n",
    "list_of_CLFs_names = []\n",
    "list_of_CLFs = [DTC, RFC, ETC]\n",
    "#list_of_CLFs = [DTC, RFC, ETC, XGB, GBM]\n",
    "ranking = []\n",
    "\n",
    "for clf in list_of_CLFs:\n",
    "    _ = clf.fit(X_train,y_train)\n",
    "    pred = clf.score(X_test,y_test)\n",
    "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
    "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
    "\n",
    "    ranking.append(pred)\n",
    "    list_of_CLFs_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlxtend error fix,https://stackoverflow.com/questions/49889524/issues-importing-mlxtend-python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@jonathan_hui/machine-learning-singular-value-decomposition-svd-principal-component-analysis-pca-1d45e885e491\n",
    "\n",
    "https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = EnsembleVoteClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.94363 for the EnsembleVoteClassifier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#refe\n",
    "#https://github.com/alik604/cyber-security/blob/master/Intrusion-Detection/UNSW_NB15.ipynb\n",
    "\n",
    "#http://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/\n",
    "\n",
    "\n",
    "#eclf = VotingClassifier(clfs=list_of_CLFs, voting='soft')  #refit=False\n",
    "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, voting='soft')  #refit=False\n",
    "_ = eclf.fit(X_train, y_train)\n",
    "pred = eclf.score(X_test, y_test)\n",
    "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
    "pred = eclf.predict(X_test)\n",
    "probas = eclf.predict_proba(X_test)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA,TruncatedSVD,PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "# Number of trees\n",
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape (154603, 10)\n",
      "Acc: 0.93326 for the DecisionTreeClassifier\n",
      "Acc: 0.94543 for the RandomForestClassifier\n",
      "Acc: 0.94063 for the ExtraTreesClassifier\n",
      "Acc: 0.94023 for the EnsembleVoteClassifier\n"
     ]
    }
   ],
   "source": [
    "#Try RFE \n",
    "\n",
    "rfe = RFE(DecisionTreeClassifier(), n).fit(X_train, y_train)\n",
    "\n",
    "desiredIndices = np.where(rfe.support_==True)[0]\n",
    "whitelist = X_train.columns.values[desiredIndices]\n",
    "X_train_RFE, X_test_RFE = X_train[whitelist], X_test[whitelist]\n",
    "\n",
    "print('new shape', X_train_RFE.shape) \n",
    "\n",
    "for clf in list_of_CLFs:\n",
    "    _ = clf.fit(X_train_RFE,y_train)\n",
    "    pred = clf.score(X_test_RFE,y_test)\n",
    "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
    "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
    "\n",
    "    ranking.append(pred)\n",
    "    list_of_CLFs_names.append(name)\n",
    "\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, voting='soft')  # refit=False,\n",
    "_ = eclf.fit(X_train_RFE, y_train)\n",
    "pred = eclf.score(X_test_RFE, y_test)\n",
    "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
    "\n",
    "\n",
    "pred = eclf.predict(X_test_RFE)\n",
    "probas = eclf.predict_proba(X_test_RFE)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>smean</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>63012</td>\n",
       "      <td>1.666667e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.163934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83653</td>\n",
       "      <td>1.556752e-02</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>1.983197e-03</td>\n",
       "      <td>0.268483</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146586</td>\n",
       "      <td>5.000001e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.360656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149380</td>\n",
       "      <td>1.500000e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67201</td>\n",
       "      <td>6.682085e-03</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.195773e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992568</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dur    sbytes    dbytes      sttl     sloss        dinpkt  \\\n",
       "63012   1.666667e-07  0.000006  0.000000  0.996078  0.000000  0.000000e+00   \n",
       "83653   1.556752e-02  0.000049  0.000207  0.243137  0.000376  1.983197e-03   \n",
       "146586  5.000001e-08  0.000006  0.000000  0.996078  0.000000  0.000000e+00   \n",
       "149380  1.500000e-07  0.000006  0.000000  0.996078  0.000000  0.000000e+00   \n",
       "67201   6.682085e-03  0.000206  0.000053  0.996078  0.000000  5.195773e-08   \n",
       "\n",
       "           stcpb     smean  ct_dst_src_ltm  ct_srv_dst  \n",
       "63012   0.000000  0.022297        0.031250    0.163934  \n",
       "83653   0.268483  0.032432        0.000000    0.000000  \n",
       "146586  0.000000  0.022297        0.343750    0.360656  \n",
       "149380  0.000000  0.022297        0.640625    0.672131  \n",
       "67201   0.000000  0.992568        0.015625    0.016393  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_RFE.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.90997 for the DecisionTreeClassifier\n",
      "Acc: 0.92177 for the RandomForestClassifier\n",
      "Acc: 0.91584 for the ExtraTreesClassifier\n",
      "Acc: 0.91608 for the EnsembleVoteClassifier\n"
     ]
    }
   ],
   "source": [
    "# Try SVD \n",
    "\n",
    "svd = TruncatedSVD(n_components=n).fit(X_train)\n",
    "X_train_svd, X_test_svd = svd.transform(X_train), svd.transform(X_test)\n",
    "\n",
    "for clf in list_of_CLFs:\n",
    "    _ = clf.fit(X_train_svd, y_train)\n",
    "    pred = clf.score(X_test_svd, y_test)\n",
    "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
    "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
    "\n",
    "    ranking.append(pred)\n",
    "    list_of_CLFs_names.append(name)\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs,  voting='soft') #refit=False,\n",
    "_ = eclf.fit(X_train_svd, y_train)\n",
    "pred = eclf.score(X_test_svd, y_test)\n",
    "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
    "\n",
    "\n",
    "pred = eclf.predict(X_test_svd)\n",
    "probas = eclf.predict_proba(X_test_svd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=n-1).fit(X_train_RFE)   \n",
    "X_train_svd, X_test_svd = svd.transform(X_train_RFE), svd.transform(X_test_RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark after additional feature removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9297176676 [DecisionTreeClassifier]\n",
      "Acc: 0.9302512855 [RandomForestClassifier]\n",
      "Acc: 0.9299893276 [ExtraTreesClassifier]\n",
      "Acc: 0.9303386048 [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DTC = DecisionTreeClassifier() \n",
    "RFC = RandomForestClassifier(n_estimators=25, random_state=1)\n",
    "ETC = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_features='auto', bootstrap=False)\n",
    "eclf = VotingClassifier(estimators=[('DecisionTreeClassifier', DTC), ('RandomForestClassifier', RFC),('ExtraTreesClassifier',ETC)], voting='hard')\n",
    "for clf, label in zip([DTC, RFC,ETC, eclf], ['DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'Ensemble']): \n",
    "        _ = eclf.fit(X_train_svd,y_train)\n",
    "        pred = eclf.score(X_test_svd,y_test)\n",
    "        print(\"Acc: %0.10f [%s]\" % (pred,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154603, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_svd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran  SVD/PCA to remove variance since the  goal to \"get the better deep learning result possible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?? why transformation here\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train_svd = mms.fit_transform(X_train_svd)\n",
    "X_test_svd = mms.transform(X_test_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train_svd\n",
    "X_t = X_test_svd\n",
    "\n",
    "dim = X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154603, 9)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(154603, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(103070, 9)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(103070, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape   \n",
    "y_train.shape\n",
    "X_t.shape \n",
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLSTM modification zone "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the dimension from 2 to 3 to run BLSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varriable mapping for RNN and BLSTM \n",
    "\n",
    "# X_v is X_train  \n",
    "# y_v is y_train \n",
    "# X  is X_train_svd\n",
    "# X_t  is X_test_svd\n",
    "# y_test is y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data set mash up to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_v ,y_v = X_t[:X_t.shape[0]/5], y_test[:X_t.shape[0]/5]\n",
    "\n",
    "X_v,y_v  = X[:X.shape[0]], y_train[:y_train.shape[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the train data set to 3 dimensional for BLSTM\n",
    "\n",
    "X_v =[]\n",
    "y_v =[]\n",
    "\n",
    "# Why do we select 60 time stamps???\n",
    "\n",
    "for i in range(60,X.shape[0] ):  \n",
    "    X_v.append(X[i-60:i])\n",
    "    y_v.append(X[i,0])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "X_v, y_v = np.array(X_v), np.array(y_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154543, 60, 9), (154543,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_v.shape, y_v.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data set mash up is done after epoch run as it causes slow epoch run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define The Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras import regularizers   # to improve loss not come nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLSTM model \n",
    "\n",
    "regressior = Sequential()\n",
    "\n",
    "regressior.add(Bidirectional(LSTM(units =60,activation = 'relu', return_sequences = True),input_shape = (X_v.shape [1],9)))  \n",
    "regressior.add(Dropout(0.07))\n",
    "\n",
    "\n",
    "regressior.add(Bidirectional(LSTM(units =60,activation = 'relu', kernel_regularizer=regularizers.l2(0.0001),return_sequences = True) ))\n",
    "regressior.add(Dropout(0.07))\n",
    "\n",
    "regressior.add(Bidirectional(LSTM(units =80,activation = 'relu', kernel_regularizer=regularizers.l2(0.0001) ,return_sequences = True) ))\n",
    "regressior.add(Dropout(0.07))\n",
    "\n",
    "regressior.add(Bidirectional(LSTM(units =90,activation = 'sigmoid',kernel_regularizer=regularizers.l2(0.0001))))\n",
    "regressior.add(Dropout(0.07))\n",
    "\n",
    "regressior.add(Dense(units = 1))  # change 10 to 1 for binary LSTM and run the neural net model from the library \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  RNN Model \n",
    "\n",
    "# classifier = Sequential()\n",
    "# #First Hidden Layer\n",
    "# classifier.add(Dense(18, activation='relu', input_dim=dim))\n",
    "# classifier.add(Dense(36, activation='relu'))\n",
    "# classifier.add(Dropout(0.07))\n",
    "# classifier.add(Dense(18, activation='relu' ))\n",
    "# classifier.add(Dropout(0.07))\n",
    "# classifier.add(Dense(9, activation='relu'))\n",
    "\n",
    "# classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RNN tensor board  \n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=f\".\\logs\\MODEL\", histogram_freq=1,write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_21 (Bidirectio (None, 60, 120)           33600     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 60, 120)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 60, 120)           86880     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 60, 120)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, 60, 160)           128640    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 60, 160)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_24 (Bidirectio (None, 180)               180720    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 181       \n",
      "=================================================================\n",
      "Total params: 430,021\n",
      "Trainable params: 430,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BLSTM regressor summary \n",
    "\n",
    "regressior.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLSTM Model note\n",
    "\n",
    "# https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "\n",
    "\n",
    "# Adam Configuration Parameters\n",
    "\n",
    "# alpha. Also referred to as the learning rate or step size. The proportion that weights are updated (e.g. 0.001). \n",
    "# Larger values (e.g. 0.3) results in faster initial learning before the rate is updated. Smaller values (e.g. 1.0E-5)\n",
    "# slow learning right down during training\n",
    "# beta1. The exponential decay rate for the first moment estimates (e.g. 0.9).\n",
    "# beta2. The exponential decay rate for the second-moment estimates (e.g. 0.999). This value should be set close to\n",
    "# 1.0 on problems with a sparse gradient (e.g. NLP and computer vision problems).\n",
    "# epsilon. Is a very small number to prevent any division by zero in the implementation (e.g. 10E-8).\n",
    "\n",
    "# The Adam paper suggests:\n",
    "\n",
    "# Good default settings for the tested machine learning problems are alpha=0.001, beta1=0.9, beta2=0.999 and \n",
    "# epsilon=10−8\n",
    "\n",
    "# The TensorFlow documentation suggests some tuning of epsilon:\n",
    "\n",
    "# The default value of 1e-8 for epsilon might not be a good default in general. For example, when training an \n",
    "# Inception network on ImageNet a current good choice is 1.0 or 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BLSTM model \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "adam= optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "#regressior.compile(optimizer = 'adam',loss = 'binary_crossentropy' ) \n",
    "\n",
    "# regressior.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy', metrics=['accuracy']))\n",
    "\n",
    "regressior.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning rate \n",
    "\n",
    "# The amount that the weights are updated during training is referred to as the step size or the “learning rate.” \n",
    "# Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has \n",
    "# a small positive value, often in the range between 0.0 and 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "154543/154543 [==============================] - 2258s 15ms/step - loss: 0.0873\n"
     ]
    }
   ],
   "source": [
    "# BLSTM Model \n",
    "\n",
    "#train test validation is too much hour \n",
    "\n",
    "#history = regressior.fit(X_v, y_v, batch_size = 10, epochs = 1, validation_data=(X_t1, y_test) ).history\n",
    "\n",
    "history = regressior.fit(X_v, y_v, batch_size = 10, epochs = 1 ).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data set mash up to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103010, 60, 9), (103010,))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# varriable assignment \n",
    "\n",
    "X_t1,y_test  = X_t[:X_t.shape[0]], y_test[:y_test.shape[0]]\n",
    "\n",
    "# Changing the validation data set to 3 dimensional for BLSTM\n",
    "\n",
    "X_t1 =[]\n",
    "y_test=[]\n",
    "\n",
    "# Why do we select 60 time stamps???\n",
    "\n",
    "for i in range(60,X_t.shape[0] ):  \n",
    "    X_t1.append(X_t[i-60:i])\n",
    "    y_test.append(X_t[i,0])\n",
    "    \n",
    "    \n",
    "# change to numpy array \n",
    "\n",
    "#X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train\n",
    "\n",
    "X_t1, y_test = np.array(X_t1), np.array(y_test)\n",
    "\n",
    "# check the converted shape \n",
    "\n",
    "X_t1.shape, y_test.shape\n",
    "\n",
    "\n",
    "# reshape array from 3d to 2d if needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Model classification out put \n",
    "\n",
    "\n",
    "# Data voloume 77301 dataset\n",
    "# the name tf.summary is deprecated. please use tf.compat.v1.summary instead\n",
    "# if you get invalid argument error when run the model use \n",
    "#tf.reset_default_graph() \n",
    "#https://stackoverflow.com/questions/51872592/invalidargumenterror-you-must-feed-a-value-for-placeholder-tensor-placeholder\n",
    "\n",
    "# from tensorflow.keras import layers, Sequential\n",
    "\n",
    "# history = classifier.fit(X,y_train, batch_size=16, epochs=10, validation_data=(X_t,y_test) , callbacks=[tensorboard]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varriable mapping for RNN and BLSTM \n",
    "\n",
    "# X_v is X_train  \n",
    "# y_v is y_train \n",
    "# X  is X_train_svd\n",
    "# X_t  is X_test_svd\n",
    "# y_test is y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN\n",
    "\n",
    "#pip install keras_sequential_ascii\n",
    "# from keras_sequential_ascii import keras2ascii\n",
    "# keras2ascii(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN \n",
    "\n",
    "#eval_model=classifier.evaluate(X, y_train )\n",
    "#print(eval_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154543/154543 [==============================] - 348s 2ms/step\n",
      "0.08373949081035402\n"
     ]
    }
   ],
   "source": [
    "#BLSTM   y_train is the same like y_v but we take 60 rows out during dimension change \n",
    "\n",
    "# reshape x_v to 2d to make prediction \n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "\n",
    "eval_model=regressior.evaluate(X_v, y_v )\n",
    "print(eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN \n",
    "\n",
    "#https://medium.com/datadriveninvestor/building-neural-network-using-keras-for-classification-3a3656c726c1\n",
    "# eval_model=classifier.evaluate(X_t, y_test)\n",
    "# print(eval_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103010/103010 [==============================] - 230s 2ms/step\n",
      "0.08361336451377142\n"
     ]
    }
   ],
   "source": [
    "#BLSTM \n",
    "eval_model=regressior.evaluate(X_t1, y_test)\n",
    "print(eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN\n",
    "\n",
    "#We now predict the output for our test dataset. If the prediction is greater than 0.5 then the output is 1 else the output is 0\n",
    "#y_pred=classifier.predict(X_t)\n",
    "#y_pred =(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLSTM \n",
    "\n",
    "y_pred=regressior.predict(X_t1)\n",
    "y_pred =(y_pred>0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103010, 1)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20426259, 0.74665767, 0.77469042, ..., 0.14910879, 0.25456511,\n",
       "       0.70684149])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103010,)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change y test to binary ( boolean )to prepare it for confusion matrix\n",
    "\n",
    "def float_to_bool(y_test):\n",
    "    if y_test > 0.5:\n",
    "        return 'True'\n",
    "    else :  \n",
    "        'False'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected sequence object with len >= 0 or a single integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-f686f517bab1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat_to_bool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: expected sequence object with len >= 0 or a single integer"
     ]
    }
   ],
   "source": [
    "y_test2 = np.ndarray(float_to_bool)(y_test).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False, False,  True])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103010,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ([False,  True,  True, True])  to      ([[ True],   [ True],   [ True]])  in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False, False,  True])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test4 = np.array(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False, False,  True])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert a flat list to list of lists in python\n",
    "# Calculate desired row/col\n",
    "row = 103010\n",
    "col = 1\n",
    "y_test3= [y_test2[col*i : col*(i+1)] for i in range(row)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103010, 1)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(y_test3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " array([False]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([ True]),\n",
       " array([False]),\n",
       " ...]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[array([False]), array([ True]) ]  vs  array([[ True] ,[ True]])\n",
    "\n",
    "#[array([0]), array([ 1]) ]  vs  array([[ 1] ,[ 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/datadriveninvestor/building-neural-network-using-keras-for-classification-3a3656c726c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 35506]\n",
      " [    0 67504]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test3, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title,fontsize=20 ,y=1.1)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix((cm),\n",
    "                      normalize    = False,\n",
    "                      target_names = ['Attack', 'Not Attack'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/confusion-matrix-machine-learning/\n",
    "# Constructing the confusion matrix.\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding precision and recall\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_test, y_pred)\n",
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the F1 score, simply call the f1_score() function:\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(X_test_svd - y_pred, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,'true_class': y_test.values.reshape(1,-1)[0]})\n",
    "# error_df.describe()\n",
    "print()\n",
    "print(np.mean(mse))\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error,pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.001, 1])\n",
    "plt.ylim([0, 1.001])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error,pos_label=1)\n",
    "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
    "plt.title('Recall vs Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.hindawi.com/journals/complexity/2019/6516253/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
