{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sourced from git hub \n",
    "\n",
    "# https://github.com/Achronus/Machine-Learning-101/blob/master/coding_templates_and_data_files/deep_learning/0.%20supervised_networks/2.%20recurrent_neural_network.py\n",
    "\n",
    "# Recurrent Neural Networks (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set source \n",
    "\n",
    "# https://www.kaggle.com/medharawat/google-stock-price?select=Google_Stock_Price_Train.csv\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('C:\\\\Users\\\\Brook\\\\Desktop\\\\#SMU_Courses\\\\#MSDS 6130 Capstone A & B\\\\MSDS6120 CapstoneA\\\\#ProjectData&NoteBook\\\\StockPrice Example_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the training set\n",
    "dataset_train = pd.read_csv('google_stock_price_train_rnn.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "\n",
    "# Feature Scaling (Normalisation)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 1258):\n",
    "    # Creates the 60 timesteps of each value. E.g. row 1 = 0 -> 59, row 2 = 1 -> 60\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    # Contains the next value after the 60 timesteps. E.g. row 1 = last value of row 2, row 2 = last value of row 3\n",
    "    # This is used to predict the next value (future value)\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "# Convert to numpy array to be accepted in our RNN\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Reshaping - adding a new dimension\n",
    "\"\"\"\n",
    "Need to convert the array to a 3 dimension to be able to permit it into the RNN.\n",
    "Keras requires 3 arguments for the input shape for this to work.\n",
    "(batch_size, timesteps, input_dim)\n",
    "batch_size - number of observations (1,198)\n",
    "timesteps - number of time steps (60)\n",
    "input_dim - number of indicators/predicters (1)\n",
    "Using numpy.shape we input 0 as the first index for batch_size (outputs number of rows).\n",
    "Then we use 1 as the second index for timesteps (outputs number of columns).\n",
    "\"\"\"\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "\"\"\"\n",
    "50 neurons in our layer, return sequences is used when having additional layers.\n",
    "Input shape only needs the timesteps and input_dim as the batch_size is taken into account automatically.\n",
    "\"\"\"\n",
    "regressor.add(LSTM( units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1) ))\n",
    "# Ignore 20% of the neurons\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "# Getting the real stock price of 2017\n",
    "dataset_test = pd.read_csv('google_stock_price_test_rnn.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "# Merge the two datasets together\n",
    "dataset_total = pd.concat( (dataset_train['Open'], dataset_test['Open']), axis = 0 )\n",
    "# Take the last 60 stock prices and the test values\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "# Reformats the data into one column\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "# Transforms the inputs to be on the same feature scaling as the training set\n",
    "inputs = sc.transform(inputs)\n",
    "\n",
    "# Creating a data structure with 60 timesteps\n",
    "X_test = []\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "# Reshape to a new dimension\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Identify the predicted values\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "# Inverse the scaling to put them back to the normal values\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Tuning the RNN\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "def build_regressor(optimizer):\n",
    "    regressor = Sequential()\n",
    "    regressor.add(LSTM( units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1) ))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(LSTM(units = 50))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = 1))\n",
    "    regressor.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "    return regressor\n",
    "regressor = KerasRegressor(build_fn = build_regressor)\n",
    "\n",
    "parameters = { 'epochs' : [100, 500], 'optimizer' : ['adam', 'rmsprop'] }\n",
    "grid_search = GridSearchCV(estimator = regressor, param_grid = parameters, scoring = 'neg_mean_squared_error', cv = 2)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
